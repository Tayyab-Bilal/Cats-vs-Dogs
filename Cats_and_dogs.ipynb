{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cats_and_dogs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiF1wqE5qwWX"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13K_RSc0WF9-"
      },
      "source": [
        "\n",
        "!wget \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\"\n",
        "!unzip \"/content/kagglecatsanddogs_3367a.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1pUYkHXq5dR",
        "cellView": "form"
      },
      "source": [
        "#@title Setting up Dataset\n",
        "!wget \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\"\n",
        "!unzip \"/content/kagglecatsanddogs_3367a.zip\"\n",
        "Data_dir=\"/content/PetImages\"\n",
        "categories= [\"Dog\",\"Cat\"]\n",
        "image_size=50\n",
        "def create_training_data(Data_path,size_of_image):\n",
        "  training_data=[]\n",
        "  for category in categories:\n",
        "    path=os.path.join(Data_path,category) #get path of each class\n",
        "    class_num=categories.index(category)\n",
        "    for img in os.listdir(path):\n",
        "      try:\n",
        "        image_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n",
        "        image_array=cv2.resize(image_array,(size_of_image,size_of_image))\n",
        "        training_data.append([image_array,class_num])\n",
        "      except Exception as e:\n",
        "        pass\n",
        "  return training_data\n",
        "C_and_D=create_training_data(Data_dir,image_size)\n",
        "random.shuffle(C_and_D)\n",
        "for sample in C_and_D[:10]:\n",
        "  print(sample[1])\n",
        "\n",
        "X=[]\n",
        "y=[]\n",
        "for features, labels in C_and_D:\n",
        "    X.append(features)\n",
        "    y.append(labels)\n",
        "\n",
        "X2=np.array(X)\n",
        "X=np.array(X).reshape(-1,image_size,image_size,1)\n",
        "pickle_out=open(\"X.pickle\",\"wb\")\n",
        "pickle.dump(X,pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out=open(\"y.pickle\",\"wb\")\n",
        "pickle.dump(y,pickle_out)\n",
        "pickle_out.close()\n",
        "!cp \"/content/X.pickle\" \"/content/drive/MyDrive/DataSets/Cats and dogs/\"\n",
        "!cp \"/content/y.pickle\" \"/content/drive/MyDrive/DataSets/Cats and dogs/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtwQTC7eerIu"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/DataSets/Cats and dogs/X.pickle\" \"/content/\"\n",
        "!cp \"/content/drive/MyDrive/DataSets/Cats and dogs/y.pickle\" \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgRbl7Bz5Btm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48dcb941-1b5c-4a76-f34b-e90099b629f6"
      },
      "source": [
        "pickle_in=open(\"X.pickle\",\"rb\")\n",
        "X=pickle.load(pickle_in)\n",
        "pickle_in=open(\"y.pickle\",\"rb\")\n",
        "y=pickle.load(pickle_in)\n",
        "X=X/255.0\n",
        "y=np.array(y)\n",
        "print(len(y),len(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24946 24946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YidM3frc1H-D",
        "outputId": "84c0c9c5-cf69-4840-b7a7-d26b99c1b069"
      },
      "source": [
        "# dense_layers=[0, 1, 2] #num of dense layers used\n",
        "# layer_sizes=[32, 64, 128] #also knows as nodes\n",
        "# conv_layers=[1, 2, 3] #num of conv layers used\n",
        "\n",
        "dense_layers=[0] #num of dense layers used\n",
        "layer_sizes=[64] #also knows as nodes\n",
        "conv_layers=[3] #num of conv layers used\n",
        "\n",
        "for dense_layer in dense_layers:\n",
        "    for layer_size in layer_sizes:\n",
        "        for conv_layer in conv_layers:\n",
        "            NAME=\"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer,layer_size,dense_layer,int(time.time()))\n",
        "            tensorboad=TensorBoard(log_dir='/content/logs/{}'.format(NAME))\n",
        "\n",
        "            model =Sequential()\n",
        "            model.add(Conv2D(layer_size,(3,3),input_shape=X.shape[1:]))\n",
        "            model.add(Activation(\"relu\"))\n",
        "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "            for l in range(conv_layer-1):\n",
        "                model.add(Conv2D(layer_size,(3,3)))\n",
        "                model.add(Activation(\"relu\"))\n",
        "                model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "            model.add(Flatten())\n",
        "            for l in range(dense_layer):\n",
        "                model.add(Dense(layer_size))\n",
        "                model.add(Activation(\"relu\"))\n",
        "                model.add(Dropout(0.2))\n",
        "\n",
        "            model.add(Dense(1))\n",
        "            model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "            model.compile(loss=\"binary_crossentropy\",\n",
        "                        optimizer=\"adam\",\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "            model.fit(X,y,batch_size=32, epochs=10, validation_split=0.3,callbacks=[tensorboad])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "546/546 [==============================] - 100s 182ms/step - loss: 0.6585 - accuracy: 0.6005 - val_loss: 0.6068 - val_accuracy: 0.6730\n",
            "Epoch 2/10\n",
            "546/546 [==============================] - 99s 181ms/step - loss: 0.5882 - accuracy: 0.6909 - val_loss: 0.5562 - val_accuracy: 0.7171\n",
            "Epoch 3/10\n",
            "546/546 [==============================] - 101s 186ms/step - loss: 0.5406 - accuracy: 0.7249 - val_loss: 0.5306 - val_accuracy: 0.7377\n",
            "Epoch 4/10\n",
            "546/546 [==============================] - 100s 183ms/step - loss: 0.5070 - accuracy: 0.7529 - val_loss: 0.5065 - val_accuracy: 0.7575\n",
            "Epoch 5/10\n",
            "546/546 [==============================] - 100s 183ms/step - loss: 0.4851 - accuracy: 0.7669 - val_loss: 0.4781 - val_accuracy: 0.7746\n",
            "Epoch 6/10\n",
            "546/546 [==============================] - 101s 185ms/step - loss: 0.4603 - accuracy: 0.7838 - val_loss: 0.4829 - val_accuracy: 0.7676\n",
            "Epoch 7/10\n",
            "546/546 [==============================] - 99s 182ms/step - loss: 0.4370 - accuracy: 0.7958 - val_loss: 0.4654 - val_accuracy: 0.7805\n",
            "Epoch 8/10\n",
            "546/546 [==============================] - 99s 181ms/step - loss: 0.4185 - accuracy: 0.8071 - val_loss: 0.4440 - val_accuracy: 0.7952\n",
            "Epoch 9/10\n",
            "546/546 [==============================] - 98s 180ms/step - loss: 0.3987 - accuracy: 0.8193 - val_loss: 0.4410 - val_accuracy: 0.7940\n",
            "Epoch 10/10\n",
            "546/546 [==============================] - 99s 181ms/step - loss: 0.3814 - accuracy: 0.8297 - val_loss: 0.4652 - val_accuracy: 0.7912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5AJlpRNrans",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f1fb8f-0f92-4556-d4b8-2f3d4070c3fc"
      },
      "source": [
        "model.save(\"64x3-CNN.model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: 64x3-CNN.model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srOKS55SJsFw"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxBsWTa8KhGC"
      },
      "source": [
        "from tensorboard import notebook\n",
        "notebook.list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwxMse9qU3yB"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/DataSets/Cats and dogs/cat1.jpeg\" \"/content/\"\n",
        "!cp \"/content/drive/MyDrive/DataSets/Cats and dogs/dog1.jpeg\" \"/content/\"\n",
        "!cp \"/content/drive/MyDrive/DataSets/Cats and dogs/dog2.jpeg\" \"/content/\"\n",
        "!cp \"/content/drive/MyDrive/DataSets/Cats and dogs/dog3.jpeg\" \"/content/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9Dv7gDQRKiu"
      },
      "source": [
        "def prepare(filepath):\n",
        "    IMG_SIZE=50\n",
        "    img_array=cv2.imread(filepath,cv2.IMREAD_GRAYSCALE)\n",
        "    new_array=cv2.resize(img_array,(IMG_SIZE,IMG_SIZE))\n",
        "    return new_array.reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
        "\n",
        "model=tf.keras.models.load_model(\"64x3-CNN.model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mlfDWiJVvhA"
      },
      "source": [
        "print(model.predict(prepare(\"/content/dog1.jpeg\")))\n",
        "print(model.predict(prepare(\"/content/cat1.jpeg\")))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}